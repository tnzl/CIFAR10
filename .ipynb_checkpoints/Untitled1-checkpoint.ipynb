{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble dataset\n",
    "def get_matrices():\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in list(range(1, 6)):\n",
    "        xx, yy = load_batch(i)\n",
    "        xx, yy = preprocess(xx, yy)\n",
    "        data.append(xx)\n",
    "        labels.append(yy)\n",
    "    \n",
    "    x_tr = np.concatenate(data)\n",
    "    y_tr = np.concatenate(labels)\n",
    "\n",
    "    x_te, y_te = load_batch(999, test=True)\n",
    "    x_te, y_te = preprocess(x_te, y_te)\n",
    "\n",
    "    print('x_tr shape: '+ str(x_tr.shape))\n",
    "    print('y_tr shape: '+ str(y_tr.shape))\n",
    "    print('\\nx_tr dtype: '+ str(x_tr.dtype))\n",
    "    print('y_tr dtype: '+ str(y_tr.dtype))\n",
    "    print('\\nx_te shape: '+ str(x_te.shape))\n",
    "    print('y_te shape: '+ str(y_te.shape))\n",
    "    print('\\nx_te dtype: '+ str(x_te.dtype))\n",
    "    print('y_te dtype: '+ str(y_te.dtype))  \n",
    "    \n",
    "    return x_tr, y_tr, x_te, y_te\n",
    "    \n",
    "# Load dataset from memory\n",
    "def load_batch(i, test = False):\n",
    "    def unpickle(file):\n",
    "        import pickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    \n",
    "    d = {}\n",
    "    if test:\n",
    "        d = unpickle('./cifar-10-batches-py/test_batch')\n",
    "    else:\n",
    "        d = unpickle('./cifar-10-batches-py/data_batch_'+str(i))\n",
    "    \n",
    "    return d[b'data'], d[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process functions here \n",
    "\n",
    "# Assemble pre-processes\n",
    "def preprocess(x, y):\n",
    "    \n",
    "    # ohe\n",
    "    y = OneHotEncoder().fit_transform(np.array(y).reshape(-1,1)).toarray()\n",
    "    \n",
    "    # reshape x\n",
    "    x = x.reshape((x.shape[0], 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    \n",
    "    # as float16\n",
    "    x = x.astype('float64')\n",
    "    y = y.astype('float16')\n",
    "    \n",
    "    # normalize\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions\n",
    "\n",
    "def plot_history(hist):\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(121)\n",
    "    bx=fig.add_subplot(122)\n",
    "    ax.plot(hist.history['loss'],label='loss')\n",
    "    ax.plot(hist.history['val_loss'],label='val_loss')\n",
    "    ax.set_title('loss')\n",
    "    ax.legend()\n",
    "    bx.plot(hist.history['accuracy'],label='accuracy')\n",
    "    bx.plot(hist.history['val_accuracy'],label='val_accuracy')\n",
    "    bx.set_title('accuracy')\n",
    "    bx.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_tr shape: (50000, 32, 32, 3)\n",
      "y_tr shape: (50000, 10)\n",
      "\n",
      "x_tr dtype: float64\n",
      "y_tr dtype: float16\n",
      "\n",
      "x_te shape: (10000, 32, 32, 3)\n",
      "y_te shape: (10000, 10)\n",
      "\n",
      "x_te dtype: float64\n",
      "y_te dtype: float16\n"
     ]
    }
   ],
   "source": [
    "x_tr, y_tr, x_te, y_te = get_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '3')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = np.random.randint(0,50000)\n",
    "plt.imshow((255*x[ind]).astype('int'))\n",
    "plt .title(y[ind].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3)),\n",
    "    tf.keras.layers.Conv2D(16, (1,1)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation= tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(10, activation= tf.keras.activations.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 22s 545us/sample - loss: 4.0366 - accuracy: 0.0969 - val_loss: 2.3041 - val_accuracy: 0.0997\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 25s 613us/sample - loss: 2.3039 - accuracy: 0.0994 - val_loss: 2.3034 - val_accuracy: 0.1025\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 26s 655us/sample - loss: 2.3039 - accuracy: 0.0990 - val_loss: 2.3035 - val_accuracy: 0.0977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f80b01c6080>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BasicModel, self).__init__()\n",
    "        self.c1  = tf.keras.layers.Conv2D(35, (3,3))\n",
    "        self.c2  = tf.keras.layers.Conv2D(40, (3,3))\n",
    "        self.c3  = tf.keras.layers.Conv2D(40, (1,1))\n",
    "        self.f1 = tf.keras.layers.Flatten()\n",
    "        self.d1 = tf.keras.layers.Dense(146, activation= tf.keras.activations.relu)\n",
    "        self.d2 = tf.keras.layers.Dense(81, activation= tf.keras.activations.relu)\n",
    "        self.d3 = tf.keras.layers.Dense(10, activation= tf.keras.activations.softmax)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.c1(inputs)\n",
    "        x = self.c2(x)\n",
    "        x = self.c3(x)\n",
    "        x = self.f1(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.d3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicModel()\n",
    "\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=3e-3)\n",
    "loss=tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "model.compile(optimizer,loss,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"basic_model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           multiple                  980       \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           multiple                  12640     \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           multiple                  1640      \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             multiple                  4578706   \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             multiple                  11907     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             multiple                  820       \n",
      "=================================================================\n",
      "Total params: 4,606,693\n",
      "Trainable params: 4,606,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build((None, 32, 32, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "   32/50000 [..............................] - ETA: 17:52:52"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-41b61a0b2090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/Projects/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Projects/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_tr, y_tr, epochs= 7,validation_data=(x_te, y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
